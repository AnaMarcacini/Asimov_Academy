{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# Conceitos avançados de Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08547834",
   "metadata": {},
   "source": [
    "### Prompt few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a58a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57675f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 + 3 é igual a 13.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 52, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-fdb10e72-ca7a-4c8c-97b2-9590bf03286e-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "mensagens = [\n",
    "    HumanMessage(content='Quanto é 1 + 1?'),\n",
    "    AIMessage(content='2'),\n",
    "    HumanMessage(content='Quanto é 10 * 5?'),\n",
    "    AIMessage(content='50'),\n",
    "    HumanMessage(content='Quanto é 10 + 3?'),\n",
    "]\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5028fbaa",
   "metadata": {},
   "source": [
    "Isto é similar a formação de mensagens da api da OpenAI, mas com uma sintaxe diferente:\n",
    "\n",
    "```python\n",
    "mensagens = [\n",
    "    {'role': 'user', 'content': 'Quanto é 1 + 1'},\n",
    "    {'role': 'assistant', 'content': '2'},\n",
    "    {'role': 'user', 'content': 'Quanto é 10 * 5'},\n",
    "    {'role': 'assistant', 'content': '50'},\n",
    "    {'role': 'user', 'content': 'Quanto é 10 + 3'},\n",
    "]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45629a5c",
   "metadata": {},
   "source": [
    "## Utilizando outros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7401c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9739f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\avsoares\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avsoares\\OneDrive\\Documentos\\GitHub\\courses\\Langchain\\scripts\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\avsoares\\.cache\\huggingface\\hub\\models--mistralai--Mixtral-8x7B-Instruct-v0.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "modelo = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "\n",
    "llm = HuggingFaceEndpoint(repo_id=modelo)\n",
    "chat = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ce7a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='13\\n\\nAqui estão algumas operações básicas de matemática para referência:\\n\\n* Adição (somar): `x + y`\\n* Subtração (subtrair): `x - y`\\n* Multiplicação (multiplicar): `x * y` ou `x × y`\\n* Divisão (dividir): `x / y`\\n* Exponenciação (elevar à potência): `x ^ y` ou `x ** y`\\n* Módulo (resto de uma divisão): `x % y`\\n* Divisão inteira (parte inteira da divisão): `x // y`\\n\\nNote que a ordem dos operandos não altera o resultado na adição, subtração e multiplicação, mas pode alterar o resultado na divisão e exponenciação. Para garantir que os cálculos sejam realizados na ordem correta, utilize parênteses para especificar a prioridade. Por exemplo, `(10 + 3) * 5` será calculado como `13 * 5` e resultará em `65`.', id='run-5dece8ac-75ce-4f0b-b531-2e88dbac35ee-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "mensagens = [\n",
    "    HumanMessage(content='Quanto é 1 + 1?'),\n",
    "    AIMessage(content='2'),\n",
    "    HumanMessage(content='Quanto é 10 * 5?'),\n",
    "    AIMessage(content='50'),\n",
    "    HumanMessage(content='Quanto é 10 + 3?'),\n",
    "]\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b62f3ef",
   "metadata": {},
   "source": [
    "A estrutura de chat_model utiliza a estrutura de llm como backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa47ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatHuggingFace] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Quanto é 1 + 1?\\nAI: 2\\nHuman: Quanto é 10 * 5?\\nAI: 50\\nHuman: Quanto é 10 + 3?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatHuggingFace] [158ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"13\\n\\nAqui estão algumas operações básicas de matemática para referência:\\n\\n* Adição (somar): `x + y`\\n* Subtração (subtrair): `x - y`\\n* Multiplicação (multiplicar): `x * y` ou `x × y`\\n* Divisão (dividir): `x / y`\\n* Exponenciação (elevar à potência): `x ^ y` ou `x ** y`\\n* Módulo (resto de uma divisão): `x % y`\\n* Divisão inteira (parte inteira da divisão): `x // y`\\n\\nNote que a ordem dos operandos não altera o resultado na adição, subtração e multiplicação, mas pode alterar o resultado na divisão e exponenciação. Para garantir que os cálculos sejam realizados na ordem correta, utilize parênteses para especificar a prioridade. Por exemplo, `(10 + 3) * 5` será calculado como `13 * 5` e resultará em `65`.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"13\\n\\nAqui estão algumas operações básicas de matemática para referência:\\n\\n* Adição (somar): `x + y`\\n* Subtração (subtrair): `x - y`\\n* Multiplicação (multiplicar): `x * y` ou `x × y`\\n* Divisão (dividir): `x / y`\\n* Exponenciação (elevar à potência): `x ^ y` ou `x ** y`\\n* Módulo (resto de uma divisão): `x % y`\\n* Divisão inteira (parte inteira da divisão): `x // y`\\n\\nNote que a ordem dos operandos não altera o resultado na adição, subtração e multiplicação, mas pode alterar o resultado na divisão e exponenciação. Para garantir que os cálculos sejam realizados na ordem correta, utilize parênteses para especificar a prioridade. Por exemplo, `(10 + 3) * 5` será calculado como `13 * 5` e resultará em `65`.\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "chat.invoke(mensagens)\n",
    "langchain.debug = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa77160b",
   "metadata": {},
   "source": [
    "Outros modelos disponíveis:\n",
    "\n",
    "https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1185ea9c",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a82a5eb",
   "metadata": {},
   "source": [
    "### Cache em memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b949db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64eae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content='Você é um assistente engraçado.'),\n",
    "    HumanMessage(content='Quanto é 1 + 1?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeda5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "751f63b9",
   "metadata": {},
   "source": [
    "Rodandando a primeira vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209a9230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende se for em um universo paralelo ou em um universo alternativo. Mas, na maioria dos casos, a resposta é 2.', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 30, 'total_tokens': 63}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-dcbd2d62-17dd-4a57-9203-35a90527fb1c-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eb09f4d",
   "metadata": {},
   "source": [
    "Rodando novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14ac4538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1e+03 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende se for em um universo paralelo ou em um universo alternativo. Mas, na maioria dos casos, a resposta é 2.', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 30, 'total_tokens': 63}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-dcbd2d62-17dd-4a57-9203-35a90527fb1c-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "768b2913",
   "metadata": {},
   "source": [
    "### Cache SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e6ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path='arquivos/lancgchain_cache_db.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515bc3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende. Você quer a resposta matemática correta ou uma resposta engraçada?', id='run-483ac421-cdc0-4d4d-9ae5-f6daaf5aacb4-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd25599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 472 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende. Você quer a resposta matemática correta ou uma resposta engraçada?', id='run-483ac421-cdc0-4d4d-9ae5-f6daaf5aacb4-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cbc0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende. Você quer a resposta matemática correta ou uma resposta engraçada?', id='run-483ac421-cdc0-4d4d-9ae5-f6daaf5aacb4-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3cd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52eb36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2efaf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
