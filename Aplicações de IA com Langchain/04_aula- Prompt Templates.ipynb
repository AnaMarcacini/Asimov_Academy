{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74684558",
   "metadata": {},
   "source": [
    "Um prompt para um modelo de linguagem é um conjunto de instruções ou entradas fornecidas por um usuário para guiar a resposta do modelo, ajudando-o a entender o contexto e gerar uma saída baseada em linguagem relevante e coerente, como responder a perguntas, completar frases ou participar de uma conversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b990d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain_openai in /home/anamarcacini/.local/lib/python3.10/site-packages (0.1.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain_openai) (0.6.0)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42\n",
      "  Using cached langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain_openai) (1.20.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.8.2)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (23.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.1.129)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.0)\n",
      "Requirement already satisfied: sniffio in /home/anamarcacini/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/anamarcacini/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: tqdm>4 in /home/anamarcacini/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/anamarcacini/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/anamarcacini/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.1.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/anamarcacini/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (2.10)\n",
      "Requirement already satisfied: certifi in /home/anamarcacini/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/anamarcacini/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/anamarcacini/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/anamarcacini/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.3)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/anamarcacini/.local/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai) (3.10.7)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/anamarcacini/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/anamarcacini/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anamarcacini/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anamarcacini/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.1.0)\n",
      "Installing collected packages: langchain-core\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.7\n",
      "    Uninstalling langchain-core-0.3.7:\n",
      "      Successfully uninstalled langchain-core-0.3.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.1 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.1.52 which is incompatible.\n",
      "langchain-text-splitters 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.1.52 which is incompatible.\n",
      "langchain-community 0.3.1 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.1.52 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.1.52\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbc0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3053195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['pergunta'], template='\\nResponda a seguinte pergunta do usuário:\\n{pergunta}                                      \\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template('''\n",
    "Responda a seguinte pergunta do usuário:\n",
    "{pergunta}                                   \n",
    "''')\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dea2724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a seguinte pergunta do usuário:\n",
      "O que é um buraco negro?                                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(pergunta='O que é um buraco negro?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a1653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResponda a seguinte pergunta do usuário em até 10 palavras:\\nO que é um buraco negro?                                   \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template('''\n",
    "Responda a seguinte pergunta do usuário em até {n_palvras} palavras:\n",
    "{pergunta}                                   \n",
    "''')\n",
    "prompt_template.format(n_palvras=10, pergunta='O que é um buraco negro?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f3b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResponda a seguinte pergunta do usuário em até 10 palavras:\\nO que é um buraco negro?                                   \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template('''\n",
    "Responda a seguinte pergunta do usuário em até {n_palvras} palavras:\n",
    "{pergunta}                                   \n",
    "''', partial_variables={'n_palvras': 10})# default 10\n",
    "prompt_template.format(pergunta='O que é um buraco negro?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7c80ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResponda a seguinte pergunta do usuário em até 5 palavras:\\nO que é um buraco negro?                                   \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(n_palvras=5, pergunta='O que é um buraco negro?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07d863c4",
   "metadata": {},
   "source": [
    "## Composing prompts | Unindo múltiplos prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6bba172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResponda a pergunta em até {n_palavras} palavras.\\nRetorn a resposta na {lingua}.\\nResponda a pergunta seguinte seguindo as instruções: {pergunta}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template_word_count = PromptTemplate.from_template('''\n",
    "Responda a pergunta em até {n_palavras} palavras.''')\n",
    "\n",
    "template_lingua = PromptTemplate.from_template('''\n",
    "Retorne a resposta na {lingua}.''')\n",
    "\n",
    "template_final = (\n",
    "    template_word_count\n",
    "    + template_lingua\n",
    "    + '\\nResponda a pergunta seguinte seguindo as instruções: {pergunta}'\n",
    ")\n",
    "\n",
    "template_final.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa109f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a pergunta em até 10 palavras.\n",
      "Retorn a resposta na inglês.\n",
      "Responda a pergunta seguinte seguindo as instruções: O que é uma estrela?\n"
     ]
    }
   ],
   "source": [
    "prompt = template_final.format(n_palavras=10, lingua='inglês', pergunta='O que é uma estrela?')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b57d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nA star is a luminous ball of gas.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = template_final.format(n_palavras=10, lingua='inglês', pergunta='O que é uma estrela?')\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ed565fb",
   "metadata": {},
   "source": [
    "## Templates para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf9d1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Essa é a minha dúvida: Quem sou eu?')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template('Essa é a minha dúvida: {duvida}')\n",
    "chat_template.format_messages(duvida='Quem sou eu?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aedded29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['nome_assistente', 'pergunta'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['nome_assistente'], template='Você é um assistente engraçado e se chama {nome_assistente}')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Olá, como vai?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Melhor agora! como posso ajudá-lo?')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pergunta'], template='{pergunta}'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'Você é um assistente engraçado e se chama {nome_assistente}'),\n",
    "        ('human', 'Olá, como vai?'),\n",
    "        ('ai', 'Melhor agora! como posso ajudá-lo?'),\n",
    "        ('human', '{pergunta}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02c0f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Você é um assistente engraçado e se chama Asimo'),\n",
       " HumanMessage(content='Olá, como vai?'),\n",
       " AIMessage(content='Melhor agora! como posso ajudá-lo?'),\n",
       " HumanMessage(content='Qual o seu nome?')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format_messages(nome_assistente='Asimo', pergunta='Qual o seu nome?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e8d7fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Meu nome é Asimo, o assistente engraçado! Como posso alegrar o seu dia hoje?', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 56, 'total_tokens': 82}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-1ac33b1c-773a-4e73-aeec-dc8c4c535763-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "chat.invoke(chat_template.format_messages(nome_assistente='Asimo', pergunta='Qual o seu nome?'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aeb5626f",
   "metadata": {},
   "source": [
    "## Templates de Few-shot prompting para llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "537fd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = [\n",
    "    {\"pergunta\": \"Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \n",
    "Resposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \n",
    "Pergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \n",
    "Resposta intermediária: Alan Turing tinha 41 anos quando morreu. \n",
    "Então a resposta final é: Muhammad Ali \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quando nasceu o fundador do craigslist?\", \n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi o fundador do craigslist? \n",
    "Resposta intermediária: O craigslist foi fundado por Craig Newmark. \n",
    "Pergunta de acompanhamento: Quando nasceu Craig Newmark? \n",
    "Resposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \n",
    "Então a resposta final é: 6 de dezembro de 1952 \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem foi o avô materno de George Washington?\",\n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi a mãe de George Washington? \n",
    "Resposta intermediária: A mãe de George Washington foi Mary Ball Washington. \n",
    "Pergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \n",
    "Resposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \n",
    "Então a resposta final é: Joseph Ball \n",
    "\"\"\", \n",
    "    },\n",
    "    {\"pergunta\": \"Os diretores de Jaws e Casino Royale são do mesmo país?\", \n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem é o diretor de Jaws? \n",
    "Resposta Intermediária: O diretor de Jaws é Steven Spielberg. \n",
    "Pergunta de acompanhamento: De onde é Steven Spielberg? \n",
    "Resposta Intermediária: Estados Unidos. \n",
    "Pergunta de acompanhamento: Quem é o diretor de Casino Royale? \n",
    "Resposta Intermediária: O diretor de Casino Royale é Martin Campbell. \n",
    "Pergunta de acompanhamento: De onde é Martin Campbell? \n",
    "Resposta Intermediária: Nova Zelândia. \n",
    "Então a resposta final é: Não \n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddb84648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \\nResposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \\nPergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \\nResposta intermediária: Alan Turing tinha 41 anos quando morreu. \\nEntão a resposta final é: Muhammad Ali \\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['pergunta', 'resposta'],\n",
    "    template='Pergunta {pergunta}\\n{resposta}'\n",
    ")\n",
    "\n",
    "example_prompt.format(**exemplos[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b8fc51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['input'], examples=[{'pergunta': 'Quem viveu mais tempo, Muhammad Ali ou Alan Turing?', 'resposta': 'São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \\nResposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \\nPergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \\nResposta intermediária: Alan Turing tinha 41 anos quando morreu. \\nEntão a resposta final é: Muhammad Ali \\n'}, {'pergunta': 'Quando nasceu o fundador do craigslist?', 'resposta': 'São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quem foi o fundador do craigslist? \\nResposta intermediária: O craigslist foi fundado por Craig Newmark. \\nPergunta de acompanhamento: Quando nasceu Craig Newmark? \\nResposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \\nEntão a resposta final é: 6 de dezembro de 1952 \\n'}, {'pergunta': 'Quem foi o avô materno de George Washington?', 'resposta': 'São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quem foi a mãe de George Washington? \\nResposta intermediária: A mãe de George Washington foi Mary Ball Washington. \\nPergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \\nResposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \\nEntão a resposta final é: Joseph Ball \\n'}, {'pergunta': 'Os diretores de Jaws e Casino Royale são do mesmo país?', 'resposta': 'São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quem é o diretor de Jaws? \\nResposta Intermediária: O diretor de Jaws é Steven Spielberg. \\nPergunta de acompanhamento: De onde é Steven Spielberg? \\nResposta Intermediária: Estados Unidos. \\nPergunta de acompanhamento: Quem é o diretor de Casino Royale? \\nResposta Intermediária: O diretor de Casino Royale é Martin Campbell. \\nPergunta de acompanhamento: De onde é Martin Campbell? \\nResposta Intermediária: Nova Zelândia. \\nEntão a resposta final é: Não \\n'}], example_prompt=PromptTemplate(input_variables=['pergunta', 'resposta'], template='Pergunta {pergunta}\\n{resposta}'), suffix='Pergunta: {input}')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix='Pergunta: {input}',\n",
    "    input_variables=['input']\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a9a74d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \n",
      "Resposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \n",
      "Pergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \n",
      "Resposta intermediária: Alan Turing tinha 41 anos quando morreu. \n",
      "Então a resposta final é: Muhammad Ali \n",
      "\n",
      "\n",
      "Pergunta Quando nasceu o fundador do craigslist?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quem foi o fundador do craigslist? \n",
      "Resposta intermediária: O craigslist foi fundado por Craig Newmark. \n",
      "Pergunta de acompanhamento: Quando nasceu Craig Newmark? \n",
      "Resposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \n",
      "Então a resposta final é: 6 de dezembro de 1952 \n",
      "\n",
      "\n",
      "Pergunta Quem foi o avô materno de George Washington?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quem foi a mãe de George Washington? \n",
      "Resposta intermediária: A mãe de George Washington foi Mary Ball Washington. \n",
      "Pergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \n",
      "Resposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \n",
      "Então a resposta final é: Joseph Ball \n",
      "\n",
      "\n",
      "Pergunta Os diretores de Jaws e Casino Royale são do mesmo país?\n",
      "São necessárias perguntas de acompanhamento aqui: Sim. \n",
      "Pergunta de acompanhamento: Quem é o diretor de Jaws? \n",
      "Resposta Intermediária: O diretor de Jaws é Steven Spielberg. \n",
      "Pergunta de acompanhamento: De onde é Steven Spielberg? \n",
      "Resposta Intermediária: Estados Unidos. \n",
      "Pergunta de acompanhamento: Quem é o diretor de Casino Royale? \n",
      "Resposta Intermediária: O diretor de Casino Royale é Martin Campbell. \n",
      "Pergunta de acompanhamento: De onde é Martin Campbell? \n",
      "Resposta Intermediária: Nova Zelândia. \n",
      "Então a resposta final é: Não \n",
      "\n",
      "\n",
      "Pergunta: Quem fez mais gols, Romário ou Pelé?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input='Quem fez mais gols, Romário ou Pelé?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91a70fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSão necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos gols Romário fez em sua carreira? \\nResposta intermediária: Romário fez 772 gols em sua carreira. \\nPergunta de acompanhamento: Quantos gols Pelé fez em sua carreira? \\nResposta intermediária: Pelé fez 1281 gols em sua carreira. \\nEntão a resposta final é: Pelé'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt.format(input='Quem fez mais gols, Romário ou Pelé?'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9420163",
   "metadata": {},
   "source": [
    "## Templates de Few-shot prompting para chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cab3e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b74c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Quem viveu mais tempo, Muhammad Ali ou Alan Turing?'), AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \\nResposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \\nPergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \\nResposta intermediária: Alan Turing tinha 41 anos quando morreu. \\nEntão a resposta final é: Muhammad Ali \\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [('human', '{pergunta}'),\n",
    "     ('ai', '{resposta}')]\n",
    ")\n",
    "\n",
    "print(example_prompt.format_messages(**exemplos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cdc0385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Quem viveu mais tempo, Muhammad Ali ou Alan Turing?'),\n",
       " AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \\nResposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \\nPergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \\nResposta intermediária: Alan Turing tinha 41 anos quando morreu. \\nEntão a resposta final é: Muhammad Ali \\n'),\n",
       " HumanMessage(content='Quando nasceu o fundador do craigslist?'),\n",
       " AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quem foi o fundador do craigslist? \\nResposta intermediária: O craigslist foi fundado por Craig Newmark. \\nPergunta de acompanhamento: Quando nasceu Craig Newmark? \\nResposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \\nEntão a resposta final é: 6 de dezembro de 1952 \\n'),\n",
       " HumanMessage(content='Quem foi o avô materno de George Washington?'),\n",
       " AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quem foi a mãe de George Washington? \\nResposta intermediária: A mãe de George Washington foi Mary Ball Washington. \\nPergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \\nResposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \\nEntão a resposta final é: Joseph Ball \\n'),\n",
       " HumanMessage(content='Os diretores de Jaws e Casino Royale são do mesmo país?'),\n",
       " AIMessage(content='São necessárias perguntas de acompanhamento aqui: Sim. \\nPergunta de acompanhamento: Quem é o diretor de Jaws? \\nResposta Intermediária: O diretor de Jaws é Steven Spielberg. \\nPergunta de acompanhamento: De onde é Steven Spielberg? \\nResposta Intermediária: Estados Unidos. \\nPergunta de acompanhamento: Quem é o diretor de Casino Royale? \\nResposta Intermediária: O diretor de Casino Royale é Martin Campbell. \\nPergunta de acompanhamento: De onde é Martin Campbell? \\nResposta Intermediária: Nova Zelândia. \\nEntão a resposta final é: Não \\n'),\n",
       " HumanMessage(content='Quem fez mais gols, Romário ou Pelé?')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_prompt\n",
    ")\n",
    "# few_shot_template.format_messages()\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    few_shot_template,\n",
    "    ('human', '{input}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format_messages(input='Quem fez mais gols, Romário ou Pelé?')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f1049b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O jogador que marcou mais gols em sua carreira foi Pelé, com mais de 1.000 gols registrados. Romário, por sua vez, marcou mais de 700 gols em sua carreira. Portanto, Pelé fez mais gols do que Romário.', response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 538, 'total_tokens': 601}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-3dd9297b-fdf0-4dbd-9326-9cb019ee3bf6-0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287c7443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
