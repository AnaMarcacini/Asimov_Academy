{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d7fc40",
   "metadata": {},
   "source": [
    "# RouterChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14ce0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c480bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fis_template = ChatPromptTemplate.from_template(\"\"\"Você é um professor de física muito inteligente.\n",
    "Você é ótimo em responder perguntas sobre física de forma concisa\n",
    "e fácil de entender.\n",
    "Quando você não sabe a resposta para uma pergunta, você admite\n",
    "que não sabe.\n",
    "\n",
    "Aqui está uma pergunta: {input}\"\"\")\n",
    "\n",
    "mat_template = ChatPromptTemplate.from_template(\"\"\"Você é um matemático muito bom.\n",
    "Você é ótimo em responder perguntas de matemática.\n",
    "Você é tão bom porque consegue decompor\n",
    "problemas difíceis em suas partes componentes, \n",
    "responder às partes componentes e depois juntá-las\n",
    "para responder à pergunta mais ampla.\n",
    "\n",
    "Aqui está uma pergunta: {input}\"\"\")\n",
    "\n",
    "hist_template = ChatPromptTemplate.from_template(\"\"\"Você é um historiador muito bom.\n",
    "Você tem um excelente conhecimento e compreensão de pessoas,\n",
    "eventos e contextos de uma variedade de períodos históricos.\n",
    "Você tem a capacidade de pensar, refletir, debater, discutir e\n",
    "avaliar o passado. Você tem respeito pela evidência histórica\n",
    "e a capacidade de usá-la para apoiar suas explicações\n",
    "e julgamentos.\n",
    "\n",
    "Aqui está uma pergunta: {input}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea58c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {'name': 'Fisica',\n",
    "     'description': 'Ideal para responder perguntas sobre física',\n",
    "     'prompt_template': fis_template},\n",
    "    {'name': 'Matematica',\n",
    "     'description': 'Ideal para responder perguntas sobre matemática',\n",
    "     'prompt_template': mat_template},\n",
    "    {'name': 'Historia',\n",
    "     'description': 'Ideal para responder perguntas sobre história',\n",
    "     'prompt_template': hist_template},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26828851",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e19fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fisica': LLMChain(verbose=True, prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Você é um professor de física muito inteligente.\\nVocê é ótimo em responder perguntas sobre física de forma concisa\\ne fácil de entender.\\nQuando você não sabe a resposta para uma pergunta, você admite\\nque não sabe.\\n\\nAqui está uma pergunta: {input}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001723F670650>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001723F0448D0>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='')),\n",
       " 'Matematica': LLMChain(verbose=True, prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Você é um matemático muito bom.\\nVocê é ótimo em responder perguntas de matemática.\\nVocê é tão bom porque consegue decompor\\nproblemas difíceis em suas partes componentes, \\nresponder às partes componentes e depois juntá-las\\npara responder à pergunta mais ampla.\\n\\nAqui está uma pergunta: {input}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001723F670650>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001723F0448D0>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy='')),\n",
       " 'Historia': LLMChain(verbose=True, prompt=ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Você é um historiador muito bom.\\nVocê tem um excelente conhecimento e compreensão de pessoas,\\neventos e contextos de uma variedade de períodos históricos.\\nVocê tem a capacidade de pensar, refletir, debater, discutir e\\navaliar o passado. Você tem respeito pela evidência histórica\\ne a capacidade de usá-la para apoiar suas explicações\\ne julgamentos.\\n\\nAqui está uma pergunta: {input}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001723F670650>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001723F0448D0>, model_name='gpt-3.5-turbo-0125', openai_api_key=SecretStr('**********'), openai_proxy=''))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains_destino = {}\n",
    "for info in prompt_infos:\n",
    "    chain = LLMChain(llm=chat, prompt=info['prompt_template'], verbose=True)\n",
    "    chains_destino[info['name']] = chain\n",
    "\n",
    "chains_destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7351613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995e407e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Fisica',\n",
       "  'description': 'Ideal para responder perguntas sobre física',\n",
       "  'prompt_template': ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Você é um professor de física muito inteligente.\\nVocê é ótimo em responder perguntas sobre física de forma concisa\\ne fácil de entender.\\nQuando você não sabe a resposta para uma pergunta, você admite\\nque não sabe.\\n\\nAqui está uma pergunta: {input}'))])},\n",
       " {'name': 'Matematica',\n",
       "  'description': 'Ideal para responder perguntas sobre matemática',\n",
       "  'prompt_template': ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Você é um matemático muito bom.\\nVocê é ótimo em responder perguntas de matemática.\\nVocê é tão bom porque consegue decompor\\nproblemas difíceis em suas partes componentes, \\nresponder às partes componentes e depois juntá-las\\npara responder à pergunta mais ampla.\\n\\nAqui está uma pergunta: {input}'))])},\n",
       " {'name': 'Historia',\n",
       "  'description': 'Ideal para responder perguntas sobre história',\n",
       "  'prompt_template': ChatPromptTemplate(input_variables=['input'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Você é um historiador muito bom.\\nVocê tem um excelente conhecimento e compreensão de pessoas,\\neventos e contextos de uma variedade de períodos históricos.\\nVocê tem a capacidade de pensar, refletir, debater, discutir e\\navaliar o passado. Você tem respeito pela evidência histórica\\ne a capacidade de usá-la para apoiar suas explicações\\ne julgamentos.\\n\\nAqui está uma pergunta: {input}'))])}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63fd7c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisica: Ideal para responder perguntas sobre física\n",
      "Matematica: Ideal para responder perguntas sobre matemática\n",
      "Historia: Ideal para responder perguntas sobre história\n"
     ]
    }
   ],
   "source": [
    "destinos = [f'{p[\"name\"]}: {p[\"description\"]}' for p in prompt_infos]\n",
    "destinos_str = '\\n'.join(destinos)\n",
    "print(destinos_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5133d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "Fisica: Ideal para responder perguntas sobre física\n",
      "Matematica: Ideal para responder perguntas sobre matemática\n",
      "Historia: Ideal para responder perguntas sobre história\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinos_str\n",
    ")\n",
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bd07dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=['input'],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(chat, router_template, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7538a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template('{input}')\n",
    "default_chain = LLMChain(llm=chat, prompt=default_prompt, verbose=True)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=chains_destino,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2be0a667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Fisica: {'input': 'O que é um buraco negro?'}\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Você é um professor de física muito inteligente.\n",
      "Você é ótimo em responder perguntas sobre física de forma concisa\n",
      "e fácil de entender.\n",
      "Quando você não sabe a resposta para uma pergunta, você admite\n",
      "que não sabe.\n",
      "\n",
      "Aqui está uma pergunta: O que é um buraco negro?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'O que é um buraco negro?',\n",
       " 'text': 'Um buraco negro é uma região do espaço onde a gravidade é tão intensa que nada, nem mesmo a luz, pode escapar de seu campo gravitacional. Essa intensa gravidade é causada pela alta concentração de massa em um espaço muito pequeno. Quando uma estrela muito massiva colapsa sob sua própria gravidade, pode formar um buraco negro. Essa região é rodeada por um limite chamado de horizonte de eventos, que marca o ponto de onde a luz não pode mais escapar. Os buracos negros são objetos fascinantes e desafiadores para os cientistas estudarem.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'O que é um buraco negro?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29709c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Matematica: {'input': 'O que é uma equação quadrática?'}\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Você é um matemático muito bom.\n",
      "Você é ótimo em responder perguntas de matemática.\n",
      "Você é tão bom porque consegue decompor\n",
      "problemas difíceis em suas partes componentes, \n",
      "responder às partes componentes e depois juntá-las\n",
      "para responder à pergunta mais ampla.\n",
      "\n",
      "Aqui está uma pergunta: O que é uma equação quadrática?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'O que é uma equação quadrática?',\n",
       " 'text': 'Uma equação quadrática é uma equação polinomial de segundo grau, ou seja, uma equação na forma ax^2 + bx + c = 0, onde a, b e c são constantes e a ≠ 0. A incógnita x representa a variável da equação e as soluções da equação são os valores de x que satisfazem a igualdade. As equações quadráticas podem ter zero, uma ou duas soluções reais, dependendo do valor do discriminante (b^2 - 4ac). As soluções podem ser encontradas através da fórmula de Bhaskara ou completando o quadrado, por exemplo.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'O que é uma equação quadrática?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a56b4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Historia: {'input': 'Quando ocorreu a revolução industrial?'}\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: Você é um historiador muito bom.\n",
      "Você tem um excelente conhecimento e compreensão de pessoas,\n",
      "eventos e contextos de uma variedade de períodos históricos.\n",
      "Você tem a capacidade de pensar, refletir, debater, discutir e\n",
      "avaliar o passado. Você tem respeito pela evidência histórica\n",
      "e a capacidade de usá-la para apoiar suas explicações\n",
      "e julgamentos.\n",
      "\n",
      "Aqui está uma pergunta: Quando ocorreu a revolução industrial?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Quando ocorreu a revolução industrial?',\n",
       " 'text': 'A Revolução Industrial ocorreu principalmente no século XVIII, com início na Grã-Bretanha por volta da segunda metade do século. Esse período de transformações profundas na produção, tecnologia e organização do trabalho teve impacto significativo em todo o mundo, marcando o início da era moderna.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'Quando foi a revolução industrial?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae934254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
